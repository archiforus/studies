{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 신경망학습\n",
    "## 107p~\n",
    "\n",
    "  * 학습 : 훈련 데이터로부터 가중치 매개변수의 최적값을 자동으로 획득하는 것을 뜻함\n",
    "  * 손실함수 : 신경망이 학습할 수 있도록 해주는 지표\n",
    "  * 학습 목표 : 손실함수의 결과값을 가장 작게 만드는 가중치 매개변수를 찾는 것\n",
    "## 데이터 주도 학습\n",
    "  * 인간은 직관을 활용해 가설을 검증 (시행착오) / 기계학습은 인간을 배제하고  수집된 데이터로 부터 패턴 찾아나감\n",
    "  * 종단간 기계학습(end-to-end mashine learning) : 처음부터 끝까지, 데이터 입력에서 결과까지 사람의 개입없이 이루어짐\n",
    "## 훈련 데이터와 테스트 데이터\n",
    "  * 분리 이유: 범용성을 평가하기 위함\n",
    "  * 오버피팅 : 제한된 데이터셋에만 지나치게 최적화된 상태 (편향된 상태)\n",
    "## 손실함수\n",
    "  * 평균제곱오차(MSE:mean squared error), 크로스엔트로피 오차를 주로 사용\n",
    "  * 매개변수의 미분이 대부분의 장소에서 0이 되기 때문에 신경망 학습시 정확도accuracy를 지표로 삼아선 안된다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  1. 평균제곱오차(MSE:mean squared error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09750000000000003"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "#MSE\n",
    "def MSE(y,t):\n",
    "    return 0.5 * np.sum((y-t)**2)\n",
    "\n",
    "y = [.1, .05, .6, 0, .05, .1, 0, .1, 0, 0] # 예측한 값 '2'가 60%로 가장 확률이 높음 (예시 :mnist data set 에서 softmax 함수 출력값)\n",
    "t = [0, 0, 1, 0, 0, 0, 0, 0, 0, 0] # 실제 값 '2' (원 핫 인코딩 한 값)\n",
    "\n",
    "#MSE값 출력\n",
    "MSE(np.array(y), np.array(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5975"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#예측값이 '7'이 60%로 가장 높았을 때, MSE 구하기\n",
    "y1 = [.1, .05, .1, 0, .05, .1, 0, .6, 0, 0] # 예측한 값 '7'가 60%로 가장 확률이 높음 (예시 :mnist data set 에서 softmax 함수 출력값)\n",
    "\n",
    "MSE(np.array(y1), np.array(t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " * 1) 'y'일때, MSE=0.0975\n",
    " * 2) 'y1'일때, MSE=0.5975\n",
    " * '1'번의 경우가, MSE가 더 낮아, 그만큼 오차가 적고, 정답에 더 가깝다고 판단"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  2. 교차 엔트로피 오차(CEE: cross entropy error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.510825457099338"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def CEE(y,t):\n",
    "    delta = 1e-7\n",
    "    return - np.sum(t*np.log(y+delta))\n",
    "\n",
    "y = [.1, .05, .6, 0, .05, .1, 0, .1, 0, 0] # 예측한 값 '2'가 60%로 가장 확률이 높음 (예시 :mnist data set 에서 softmax 함수 출력값)\n",
    "t = [0, 0, 1, 0, 0, 0, 0, 0, 0, 0] # 실제 값 '2' (원 핫 인코딩 한 값)\n",
    "\n",
    "CEE(np.array(y), np.array(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.302584092994546"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#예측값이 '7'이 60%로 가장 높았을 때, MSE 구하기\n",
    "y1 = [.1, .05, .1, 0, .05, .1, 0, .6, 0, 0] # 예측한 값 '7'가 60%로 가장 확률이 높음 (예시 :mnist data set 에서 softmax 함수 출력값)\n",
    "\n",
    "CEE(np.array(y1), np.array(t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 미니배치 학습\n",
    " * 미니배치 학습 : 전체 훈련 데이터 중 일부만 무작위 추출하여 학습\n",
    " * 이유 : 모든 데이터의 손실함수를 구한다면 계산량이 많다. 일부 샘플링하여 '근사치'로 구함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n",
      "(60000, 10)\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.pardir)\n",
    "import numpy as np\n",
    "from dataset.mnist import load_mnist\n",
    "\n",
    "(x_train, t_train), (x_test, t_test) = load_mnist(normalize = True, one_hot_label = True)\n",
    "\n",
    "print(x_train.shape)\n",
    "print(t_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#random choice 활용, train data에서 무작위로 10개 추출하기\n",
    "train_size = x_train.shape[0]\n",
    "batch_size = 10\n",
    "batch_mask = np.random.choice(train_size, batch_size)\n",
    "x_batch = x_train[batch_mask]\n",
    "t_batch = t_train[batch_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch CEE (원핫 인코딩 한 경우,)\n",
    "def CEE_b_o(y,t):\n",
    "    if y.ndim ==1:\n",
    "        t = t.reshape(1, t.size)\n",
    "        y = y.reshape(1, y.size)\n",
    "        \n",
    "    batch_size = y.shape[0]\n",
    "    return -np.sum(t*np.log(y)) / batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch CEE (정답 레이블이 실제 숫자로 주어질 경우,)\n",
    "def CEE_b_r(y,t):\n",
    "    if y.ndim ==1:\n",
    "        t = t.reshape(1, t.size)\n",
    "        y = y.reshape(1, y.size)\n",
    "        \n",
    "    batch_size = y.shape[0]\n",
    "    return -np.sum(np.log(y[np.arange(batch_size),t])) / batch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 수치 미분\n",
    " * 수치미분과 진정한 미분 사이의 차이를 극복하기 위해 중심차분(중앙차분)을 계산한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#수치미분\n",
    "def numerical_diff(f,x):\n",
    "    h = 1e-4 #0.0001을 의미 (미분시 lim h->0 의 개략적 표현)\n",
    "    return (f(x+h) - f(x-h)) / (2*h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#수치미분 예시\n",
    "def function_1(x):\n",
    "    return 0.01*x**2 + 0.1*x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pylab as plt\n",
    "\n",
    "x = np.arange(0.0, 20.0, 0.1) # 0-20까지 0.1간격의 배열 x\n",
    "y = function_1(x)\n",
    "\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('f(x)')\n",
    "plt.plot(x,y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1999999999990898\n",
      "0.2999999999986347\n"
     ]
    }
   ],
   "source": [
    "print(numerical_diff(function_1, 5)) #실제 미분값은 0.2\n",
    "print(numerical_diff(function_1, 10)) #실제 미분값은 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 편미분\n",
    "def function_2(x):     #f(x0, x1) = x0^2 + x1^2\n",
    "    return x[0]**2 + x[1]**2 #또는 return np.sum(x**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.00000000000378"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 예제 x0 = 3, x1=4 일때, x0에 대한 편미분을 구하라.\n",
    "def function_tmp1(x0):\n",
    "    return x0*x0 +4.0**2.0\n",
    "numerical_diff(function_tmp1, 3.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.999999999999119"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 예제 x0 = 3, x1=4 일때, x1에 대한 편미분을 구하라.\n",
    "def function_tmp2(x1):\n",
    "    return 3**2 +x1**x1\n",
    "numerical_diff(function_tmp1, 4.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numerical_gradient(f, x):\n",
    "    h = 1e-4\n",
    "    grad = np.zeros_like(x) #x와 형상이 같고 원소가 모두 0인 배열을 생성\n",
    "    \n",
    "    for idx in range(x.size):\n",
    "        tmp_val = x[idx]\n",
    "        x[idx] = tmp_val + h #f(x+h)계산\n",
    "        fxh1 = f(x)\n",
    "        \n",
    "        x[idx] = tmp_val - h #f(x-h)계산\n",
    "        fxh2 = f(x)\n",
    "        \n",
    "        grad[idx] = (fxh1 - fxh2) / (2*h)\n",
    "        x[idx] = tmp_val #값을 복원\n",
    "    \n",
    "    return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6. 8.]\n",
      "[0. 4.]\n",
      "[6. 0.]\n"
     ]
    }
   ],
   "source": [
    "#예시 (3,4),(0,2),(3,0) 에서 기울기 구하기\n",
    "\n",
    "print(numerical_gradient(function_2, np.array([3.0,4.0])))\n",
    "print(numerical_gradient(function_2, np.array([0.0,2.0])))\n",
    "print(numerical_gradient(function_2, np.array([3.0,0.0])))\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6. 8. 0. 0. 0.]\n",
      "[0. 4. 0. 0. 0.]\n",
      "[6. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "# 변수가 많은 2차 방정식을 numpy 행렬로 각각의 변수로 편미분\n",
    "\n",
    "def function_3(x):     #f(x0, x1, x2,...) = x0^2 + x1^2 + x2^3 + ....\n",
    "    return x[0]**2 + x[1]**2 + x[2]**2 + x[3]**2 + x[4]**2\n",
    "\n",
    "def numerical_gradient(f, x):\n",
    "    h = 1e-4\n",
    "    grad = np.zeros_like(x) #x와 형상이 같고 원소가 모두 0인 배열을 생성\n",
    "    \n",
    "    for idx in range(x.size):\n",
    "        tmp_val = x[idx]\n",
    "        x[idx] = tmp_val + h #f(x+h)계산\n",
    "        fxh1 = f(x)\n",
    "        \n",
    "        x[idx] = tmp_val - h #f(x-h)계산\n",
    "        fxh2 = f(x)\n",
    "        \n",
    "        grad[idx] = (fxh1 - fxh2) / (2*h)\n",
    "        x[idx] = tmp_val #값을 복원\n",
    "    \n",
    "    return grad\n",
    "\n",
    "\n",
    "print(numerical_gradient(function_2, np.array([3.0,4.0,5.0,0.0,2.0])))\n",
    "print(numerical_gradient(function_2, np.array([0.0,2.0,1.0,4.0,5.0])))\n",
    "print(numerical_gradient(function_2, np.array([3.0,0.0,1.0,5.0,0.0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 경사하강법\n",
    " * 극소값 : 기울기0, 한정된 범위 내 최소값\n",
    " * 극대값 : 기울기0, 한정된 범위 내 최대값\n",
    " * 안장점 : 기울기0, 극소값 혹은 극대값 (보는 위치에 극대, 극소로 봄)\n",
    " * 플래토plateau, 고원 : 복잡하고 찌그러진 함수의 일부 평평한 부분 (학습 정체 유발)\n",
    " * 에타, 학습률 learning rate : 한번 학습으로 얼만큼 학습할지 (매개변수 값을 얼마나 갱신할지 결정)\n",
    " * 학습률의 적정치 : 학습률을 적정 수준으로 지정하는 것이 중요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#경사하강법 구현\n",
    "def gradient_descent(f, init_x, lr=0.01, step_num=100):  #f:최적화하려는 함수 / init_x:초기값, lr:학습률, step_num:경사법에 따른 반봅 횟수\n",
    "    x = init_x\n",
    "    \n",
    "    for i in range(step_num):    #설정한 반복 횟수 만큼 반복\n",
    "        grad = numerical_gradient(f, x)    #앞서 정의한 기울기 함수로 기울기를 구한다.\n",
    "        x -=lr * grad     # 구한 기울기에 학습률을 곱한후, x값을 갱신한다.  \n",
    "    return x   #설정한 반복 횟수만큼 x 값을 갱신하고, 최종 x 값을 출력한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#경사법으로 f(x0, x1) = x0^2 + x1^2의 최소값 구하기\n",
    "def function_2(x):\n",
    "    return x[0]**2 + x[1]**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-6.11110793e-10,  8.14814391e-10])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "init_x = np.array([-3.0, 4.0])\n",
    "gradient_descent(function_2, init_x=init_x, lr=0.1, step_num = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
